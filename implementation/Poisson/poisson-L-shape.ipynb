{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PXUiSpAk8lgJ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PXUiSpAk8lgJ",
    "outputId": "9e1da6c2-6b09-41df-aeb6-2ec2fe67f147"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available!\n",
      "Device Name: Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available!\")\n",
    "    print(\"Device Name:\", torch.cuda.get_device_name(0))\n",
    "else:\n",
    "    print(\"GPU is not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1kBBEvDKJ79p",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1kBBEvDKJ79p",
    "outputId": "40392a11-2c1d-4120-e61a-3ae5eb782e17"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:22:40.363593: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1750738960.398998   34074 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1750738960.412597   34074 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1750738960.446225   34074 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750738960.446257   34074 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750738960.446262   34074 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1750738960.446265   34074 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-06-23 23:22:40.453834: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Using backend: tensorflow.compat.v1\n",
      "Other supported backends: tensorflow, pytorch, jax, paddle.\n",
      "paddle supports more examples now and is recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/oel/.venv/jupy3/lib/python3.11/site-packages/tensorflow/python/compat/v2_compat.py:98: disable_resource_variables (from tensorflow.python.ops.resource_variables_toggle) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-23 23:22:45.378685: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Polygon.uniform_points not implemented. Use random_points instead.\n",
      "--- Starting Adam optimization ---\n",
      "Compiling model...\n",
      "Building feed-forward neural network...\n",
      "'build' took 0.091564 s\n",
      "\n",
      "'compile' took 0.758661 s\n",
      "\n",
      "Training model...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1750738966.644335   34074 mlir_graph_optimization_pass.cc:425] MLIR V1 optimization pass is not enabled\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step      Train loss              Test loss               Test metric   \n",
      "0         [3.25e+01, 2.76e-01]    [4.11e+01, 2.76e-01]    [1.65e+00]    \n",
      "1000      [4.20e-03, 1.02e-02]    [3.50e-03, 1.02e-02]    [1.99e-01]    \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Solves the Poisson equation on an L-shaped domain using DeepXDE.\n",
    "\n",
    "This script trains a Physics-Informed Neural Network (PINN) and visualizes\n",
    "both the training loss history and the final solution comparison.\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.tri as tri\n",
    "import deepxde as dde\n",
    "import os\n",
    "\n",
    "# Set the backend to PyTorch for consistency.\n",
    "os.environ['DDE_BACKEND'] = 'pytorch'\n",
    "dde.config.set_random_seed(42)\n",
    "\n",
    "# --- 1. Define the Problem: Geometry, PDE, and Boundary Conditions ---\n",
    "\n",
    "# Define the L-shaped domain using the vertices of a polygon.\n",
    "# The domain is the square [-1, 1] x [-1, 1] with the quadrant [0, 1] x [-1, 0] removed.\n",
    "# The re-entrant corner at (0, 0) introduces a singularity, a classic challenge.\n",
    "vertices = [[-1, -1], [1, -1], [1, 0], [0, 0], [0, 1], [-1, 1]]\n",
    "geom = dde.geometry.Polygon(vertices)\n",
    "\n",
    "# Define the Poisson equation.\n",
    "# The forcing function f(x, y) is derived from a known analytical solution\n",
    "# to allow for rigorous validation of the network's accuracy.\n",
    "def pde(x, u):\n",
    "    \"\"\"\n",
    "    Defines the residual of the Poisson equation: ∇²u - f = 0.\n",
    "\n",
    "    Args:\n",
    "        x: A tensor of coordinates (x, y) with shape [N, 2].\n",
    "        u: The network's output tensor u(x, y) with shape [N, 1].\n",
    "\n",
    "    Returns:\n",
    "        The PDE residual tensor.\n",
    "    \"\"\"\n",
    "    # The Laplacian is computed by summing the second partial derivatives.\n",
    "    # dde.grad.hessian(u, x, i=0, j=0) computes ∂²u/∂x²\n",
    "    # dde.grad.hessian(u, x, i=1, j=1) computes ∂²u/∂y²\n",
    "    dudx2 = dde.grad.hessian(u, x, i=0, j=0)\n",
    "    dudy2 = dde.grad.hessian(u, x, i=1, j=1)\n",
    "    laplacian = dudx2 + dudy2\n",
    "\n",
    "    x_ = x[:, 0:1]\n",
    "    y_ = x[:, 1:2]\n",
    "\n",
    "    # Forcing function: f(x, y) = - (5/4)π² * sin(πx) * cos(πy / 2)\n",
    "    pi = np.pi\n",
    "    forcing_term = -(5.0 / 4.0) * pi**2 * dde.backend.sin(pi * x_) * dde.backend.cos(pi * y_ / 2.0)\n",
    "\n",
    "    return laplacian - forcing_term\n",
    "\n",
    "# Define the analytical solution used for validation and boundary conditions.\n",
    "def analytical_solution(x):\n",
    "    \"\"\"\n",
    "    Analytical solution u(x, y) = sin(πx) * cos(πy / 2).\n",
    "\n",
    "    Args:\n",
    "        x: A NumPy array of coordinates with shape [N, 2].\n",
    "\n",
    "    Returns:\n",
    "        The solution u at each coordinate.\n",
    "    \"\"\"\n",
    "    x_, y_ = x[:, 0:1], x[:, 1:2]\n",
    "    return np.sin(np.pi * x_) * np.cos(np.pi * y_ / 2.0)\n",
    "\n",
    "# The boundary condition function simply returns the analytical solution on the boundary.\n",
    "def boundary_func(x):\n",
    "    \"\"\"\n",
    "    Computes the boundary values from the analytical solution.\n",
    "    This handles the non-homogeneous part of the Dirichlet condition.\n",
    "    \"\"\"\n",
    "    return analytical_solution(x)\n",
    "\n",
    "# Create the Dirichlet Boundary Condition object.\n",
    "# The lambda function `lambda _, on_boundary: on_boundary` applies this condition\n",
    "# to all points identified by deepxde as being on the boundary of the geometry.\n",
    "bc = dde.DirichletBC(geom, boundary_func, lambda _, on_boundary: on_boundary)\n",
    "\n",
    "\n",
    "# --- 2. Create the Model and Data ---\n",
    "\n",
    "# Create the PDE data object.\n",
    "data = dde.data.PDE(\n",
    "    geom,\n",
    "    pde,\n",
    "    bc,\n",
    "    num_domain=2500,        # Collocation points for enforcing the PDE\n",
    "    num_boundary=800,       # Collocation points for enforcing the BC\n",
    "    solution=analytical_solution,\n",
    "    num_test=1000,          # Points for calculating validation error during training\n",
    ")\n",
    "\n",
    "# Define the neural network architecture.\n",
    "# Input: 2 neurons (x, y)\n",
    "# Hidden Layers: 4 layers with 50 neurons each, using the 'tanh' activation function.\n",
    "# Output: 1 neuron (u)\n",
    "net = dde.nn.FNN([2] + [50] * 4 + [1], \"tanh\", \"Glorot normal\")\n",
    "\n",
    "# Create the deepxde model.\n",
    "model = dde.Model(data, net)\n",
    "\n",
    "\n",
    "# --- 3. Train the Model ---\n",
    "\n",
    "# Stage 1: Adam optimizer for initial training.\n",
    "print(\"--- Starting Adam optimization ---\")\n",
    "model.compile(\"adam\", lr=1e-3, metrics=[\"l2 relative error\"])\n",
    "# We capture the returned history object to plot the loss evolution.\n",
    "adam_losshistory, train_state = model.train(iterations=20000)\n",
    "\n",
    "# Stage 2: L-BFGS optimizer for fine-tuning.\n",
    "# This second-order optimizer is often used after Adam to achieve higher accuracy.\n",
    "print(\"\\n--- Starting L-BFGS optimization ---\")\n",
    "model.compile(\"L-BFGS\")\n",
    "lbfgs_losshistory, train_state = model.train()\n",
    "\n",
    "\n",
    "# --- 4. Visualize Training History ---\n",
    "print(\"\\n--- Generating Loss History Plot ---\")\n",
    "\n",
    "# Extract loss data from the Adam training history\n",
    "loss_train = np.sum(adam_losshistory.loss_train, axis=1)\n",
    "loss_test = np.sum(adam_losshistory.loss_test, axis=1)\n",
    "steps = adam_losshistory.steps\n",
    "\n",
    "# Create and save the loss plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(steps, loss_train, label='Train Loss')\n",
    "plt.plot(steps, loss_test, label='Test Loss')\n",
    "plt.yscale('log')\n",
    "plt.title('Training and Test Loss History (Adam)')\n",
    "plt.xlabel('Optimization Step')\n",
    "plt.ylabel('Log-scale Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, which=\"both\", ls=\"--\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"loss_history.png\")\n",
    "print(\"Loss history plot saved to loss_history.png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# --- 5. Visualize the Final Results ---\n",
    "print(\"\\n--- Generating Final Solution Plots ---\")\n",
    "\n",
    "# Generate a dense grid of points for plotting the solution contours.\n",
    "n_points = 500\n",
    "x_range = np.linspace(-1, 1, n_points)\n",
    "y_range = np.linspace(-1, 1, n_points)\n",
    "grid_x, grid_y = np.meshgrid(x_range, y_range)\n",
    "plot_points = np.hstack((grid_x.flatten()[:, None], grid_y.flatten()[:, None]))\n",
    "is_inside = geom.inside(plot_points)\n",
    "plot_points_inside = plot_points[is_inside]\n",
    "\n",
    "# Make predictions on the plot points.\n",
    "u_pred = model.predict(plot_points_inside)\n",
    "# Calculate the true solution and the point-wise error.\n",
    "u_true = analytical_solution(plot_points_inside)\n",
    "error = np.abs(u_pred - u_true)\n",
    "\n",
    "# Create a triangulation for the unstructured data for contour plotting.\n",
    "triang = tri.Triangulation(plot_points_inside[:, 0], plot_points_inside[:, 1])\n",
    "\n",
    "# Create a figure with three subplots for comparison.\n",
    "fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "# Plot 1: Predicted Solution\n",
    "contour1 = axes[0].tricontourf(triang, u_pred.flatten(), levels=100, cmap='viridis')\n",
    "fig.colorbar(contour1, ax=axes[0])\n",
    "axes[0].set_title('PINN Predicted Solution $u_{NN}(x,y)$')\n",
    "axes[0].set_xlabel('$x$')\n",
    "axes[0].set_ylabel('$y$')\n",
    "axes[0].set_aspect('equal', 'box')\n",
    "\n",
    "# Plot 2: Analytical Solution\n",
    "contour2 = axes[1].tricontourf(triang, u_true.flatten(), levels=100, cmap='viridis')\n",
    "fig.colorbar(contour2, ax=axes[1])\n",
    "axes[1].set_title('Analytical Solution $u_{true}(x,y)$')\n",
    "axes[1].set_xlabel('$x$')\n",
    "axes[1].set_ylabel('$y$')\n",
    "axes[1].set_aspect('equal', 'box')\n",
    "\n",
    "# Plot 3: Absolute Error\n",
    "contour3 = axes[2].tricontourf(triang, error.flatten(), levels=100, cmap='Reds')\n",
    "fig.colorbar(contour3, ax=axes[2])\n",
    "axes[2].set_title('Absolute Error $|u_{NN} - u_{true}|$')\n",
    "axes[2].set_xlabel('$x$')\n",
    "axes[2].set_ylabel('$y$')\n",
    "axes[2].set_aspect('equal', 'box')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"poisson_l_shape_solution.png\")\n",
    "print(\"Solution comparison plot saved to poisson_l_shape_solution.png\")\n",
    "plt.show()\n",
    "\n",
    "# Finally, print the L2 relative error on the test data.\n",
    "final_error = dde.metrics.l2_relative_error(u_true, u_pred)\n",
    "print(f\"\\nFinal L2 relative error on plot points: {final_error:.4e}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
